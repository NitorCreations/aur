<html>
<head>
<title>AR Marker example with Three.js</title>
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1">
<style>
html,body {
  margin: 0;
  padding: 0;
  width: 100%;
  text-align: center;
  overflow-x: hidden;
}
.portrait canvas {
  transform-origin: 0 0;
  transform: rotate(-90deg) translateX(-100%);
}
.desktop canvas {
  transform: scale(-1, 1);
}
</style>
</head>
<body>

<!--
<p>On Chrome on Android, tap the screen to start playing video stream.</p>
<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
-->

<script src="./deps/artoolkit.debug.js"></script>
<script src="./deps/artoolkit.api.js"></script>
<script async src="./deps/three.min.js"></script>
<script async src="./deps/artoolkit.three.js"></script>

<script>

window.start = (model, deviceId) => {
  ARController.getUserMediaThreeScene({
    maxARVideoSize: 320,
    cameraParam: 'Data/camera_para-iPhone 5 rear 640x480 1.0m.dat',
    deviceId: deviceId,
  onSuccess: function(arScene, arController, arCamera) {

    document.body.className = arController.orientation;

    arController.setPatternDetectionMode(artoolkit.AR_MATRIX_CODE_DETECTION);

    var renderer = new THREE.WebGLRenderer({antialias: true});
    if (arController.orientation === 'portrait') {
      var w = (window.innerWidth / arController.videoHeight) * arController.videoWidth;
      var h = window.innerWidth;
      renderer.setSize(w, h);
      renderer.domElement.style.paddingBottom = (w-h) + 'px';
    } else {
      if (/Android|mobile|iPad|iPhone/i.test(navigator.userAgent)) {
        renderer.setSize(window.innerWidth, (window.innerWidth / arController.videoWidth) * arController.videoHeight);
      } else {
        renderer.setSize(arController.videoWidth, arController.videoHeight);
        document.body.className += ' desktop';
      }
    }

    document.body.insertBefore(renderer.domElement, document.body.firstChild);

    // See /doc/patterns/Matrix code 3x3 (72dpi)/20.png
    var markerRoot = arController.createThreeBarcodeMarker(20);

    if (!model) {
      console.log('using debug model')
      model = new THREE.Mesh(
        new THREE.SphereGeometry(0.5, 8, 8),
        new THREE.MeshNormalMaterial()
      );
      model.material.shading = THREE.FlatShading;
    }

    model.position.z = 0.5;
    markerRoot.add(model);

    arScene.scene.add(markerRoot);

    var rotationV = 0;
    var rotationTarget = 0;

    renderer.domElement.addEventListener('click', ev => {
      ev.preventDefault();
      rotationTarget += 1;
    }, false);

    var tick = () => {
      arScene.process();
      arScene.renderOn(renderer);
      rotationV += (rotationTarget - model.rotation.z) * 0.05;
      model.rotation.z += rotationV;
      rotationV *= 0.8;

      requestAnimationFrame(tick);
    };

    tick();

  }});
};

window.onload = () => {
  var pasi_material;

  var textureloader = new THREE.TextureLoader();
  textureloader.load(
    '../models/pasi_texture.jpg',
    texture => pasi_material = new THREE.MeshBasicMaterial({ map: texture })
  );

  var jsonloader = new window.THREE.JSONLoader();
  jsonloader.load(
    '../models/pasi_mesh.js',
    (geometry, materials) => {
      var object = new THREE.Mesh( geometry, pasi_material );

      // navigator.mediaDevices.enumerateDevices()
      //   .then(devices => {
      //     const cameras = devices.filter(device => device.kind === 'videoinput')
      //     const backCamera = cameras.find(camera => camera.label.indexOf('back') > -1)
      //     const deviceId = backCamera ? backCamera.deviceId : cameras[0].deviceId

      //     window.start(deviceId)
      //   })

      window.start(object);
    }
  );
}

</script>

</body>
</html>